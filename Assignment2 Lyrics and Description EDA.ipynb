{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b8add8f",
   "metadata": {},
   "source": [
    "#### Vicky van der Wagt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f79baf9",
   "metadata": {},
   "source": [
    "# ADS 509 Assignment 2.1: Tokenization, Normalization, Descriptive Statistics \n",
    "\n",
    "This notebook holds Assignment 2.1 for Module 2 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In the previous assignment you pulled lyrics data on two artists. In this assignment we explore this data set and a pull from the now-defunct Twitter API for the artists Cher and Robyn.  If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Canvas. \n",
    "\n",
    "This assignment asks you to write a short function to calculate some descriptive statistics on a piece of text. Then you are asked to find some interesting and unique statistics on your corpora. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae8e2e1",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "e2d096b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "6b555ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional import statements you need here\n",
    "\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "923b5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change `data_location` to the location of the folder on your machine.\n",
    "data_location = \"/Users/vicky/Documents/GitHub/ADS509-Assignment2.2/M1 Results/\"\n",
    "\n",
    "# These subfolders should still work if you correctly stored the \n",
    "# data from the Module 1 assignment\n",
    "twitter_folder = \"twitter/\"\n",
    "lyrics_folder = \"lyrics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "06522af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stats(tokens, num_tokens = 5, verbose=True) :\n",
    "    \"\"\"\n",
    "        Given a list of tokens, print number of tokens, number of unique tokens, \n",
    "        number of characters, lexical diversity (https://en.wikipedia.org/wiki/Lexical_diversity), \n",
    "        and num_tokens most common tokens. Return a list with the number of tokens, number\n",
    "        of unique tokens, lexical diversity, and number of characters. \n",
    "    \n",
    "    \"\"\"\n",
    "    # Fill in the correct values here. \n",
    "    num_tokens = len(tokens)\n",
    "    #print length of set of tokens (sets can't have duplicates)\n",
    "    num_unique_tokens = len(set(tokens))\n",
    "    #ratio of unique tokens to the total number of tokens\n",
    "    #added if statement just incase num_tokens is 0 which would result in error\n",
    "    lexical_diversity = num_unique_tokens / num_tokens if len(tokens) > 0 else 0\n",
    "    #for each token, count the length (# of characters)\n",
    "    num_characters = sum(len(token) for token in tokens)\n",
    "\n",
    "    if verbose :        \n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "    \n",
    "        # print the five most common tokens\n",
    "        \n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "59dcf058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 tokens in the data.\n",
      "There are 9 unique tokens in the data.\n",
      "There are 55 characters in the data.\n",
      "The lexical diversity is 0.692 in the data.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"here is some example text with other example text here in this text\"\"\".split()\n",
    "assert(descriptive_stats(text, verbose=True)[0] == 13)\n",
    "assert(descriptive_stats(text, verbose=False)[1] == 9)\n",
    "assert(abs(descriptive_stats(text, verbose=False)[2] - 0.69) < 0.02)\n",
    "assert(descriptive_stats(text, verbose=False)[3] == 55)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7e1a2",
   "metadata": {},
   "source": [
    "Q: Why is it beneficial to use assertion statements in your code? \n",
    "\n",
    "A: It is beneficial to use assertions in code because they can check that the code is working as expected. In the case of the funciton above, the correct values were known beforehand and the assert statement verified that we got the values we expected, and that the function was working as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bf93e",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "04400594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the lyrics data\n",
    "lyrics_path = os.path.join(data_location, lyrics_folder)\n",
    "\n",
    "#initialize dictionary\n",
    "lyrics_dict = {}\n",
    "\n",
    "#for every artist (folder) in lyrics path...\n",
    "for artist in os.listdir(lyrics_path):\n",
    "    #find the artist path\n",
    "    artist_path = os.path.join(lyrics_path, artist)\n",
    "    if os.path.isdir(artist_path):  \n",
    "        #initialize dictionary to hold songs\n",
    "        artist_songs = {}  \n",
    "        #for each song in artist_path\n",
    "        for song_file in os.listdir(artist_path):\n",
    "            #if a .txt file...\n",
    "            if song_file.endswith('.txt'):\n",
    "                # extract song title(after 1st  _ delimiter)\n",
    "                song_title = song_file.split(\"_\", 1)[1].split(\".\")[0]\n",
    "                song_path = os.path.join(artist_path, song_file)\n",
    "                with open(song_path, 'r', encoding='utf-8') as file:\n",
    "                    #read the file\n",
    "                    song_lyrics = file.read()  \n",
    "                    #artist_song and song_lyrics - key value pair\n",
    "                    artist_songs[song_title] = song_lyrics  \n",
    "        #nested dictionary. artist is key to the artist_songs dictionary            \n",
    "        lyrics_dict[artist] = artist_songs  # Add artist as a key to the dictionary with the nested dictionary of song titles and lyrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "debcac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the twitter data\n",
    "twitter_path = os.path.join(data_location,twitter_folder)\n",
    "\n",
    "#initialize dictionary\n",
    "description_dict = {}\n",
    "\n",
    "#for subfolder containing the word data in the twitter path\n",
    "for data_file in os.listdir(twitter_path):\n",
    "    #filter for files with data in the name\n",
    "    if \"data\" in data_file:\n",
    "        #extract artist name as text in the file name before the underscore\n",
    "        artist_name = data_file.split(\"_\")[0]\n",
    "        #make empty list for descriptions\n",
    "        description_strings = []\n",
    "        # read file\n",
    "        with open(os.path.join(twitter_path, data_file), 'r') as file:\n",
    "            # skip header line because it does not contain descriptions\n",
    "            next(file)\n",
    "            # for each line in the files...\n",
    "            for line in file:\n",
    "                # split text file into columns, tab delimited\n",
    "                columns = line.strip().split('\\t') \n",
    "                # append description to list\n",
    "                #needed to specify column length, because blank columns were creating issues\n",
    "                if len(columns) >= 7:\n",
    "                    description_strings.append(columns[6])  # Assuming the description column is the seventh column\n",
    "        # add artist name and descriptions to dictionary\n",
    "        description_dict[artist_name] = description_strings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f3b12",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Now clean and tokenize your data. Remove punctuation chacters (available in the `punctuation` object in the `string` library), split on whitespace, fold to lowercase, and remove stopwords. Store your cleaned data, which must be accessible as an interable for `descriptive_stats`, in new objects or in new columns in your data frame. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "71c73d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(punctuation) # speeds up comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "6baa36b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate data cleaning function\n",
    "def data_cleaning(data):\n",
    "    '''This function removes punctuation, folds characters to lowercase,\n",
    "        splits on whitespace, and removes stopwords. Input is a dictionary.'''\n",
    "    for key, value in data.items():\n",
    "        cleaned_values = []\n",
    "        for text in value:\n",
    "            # remove punctuation characters\n",
    "            # if character is not in punctuation, fold lowercase and string together\n",
    "            text = ''.join(char.lower() for char in text if char not in punctuation)\n",
    "            # split on whitespace (.split() splits on whitespace as default)\n",
    "            tokens = text.split()\n",
    "            # remove stop_words (generally common words) from data\n",
    "            tokens = [token for token in tokens if token not in sw]\n",
    "            # Join the cleaned tokens back into a string\n",
    "            cleaned_values.append(' '.join(tokens))\n",
    "        # Update the value of the original dictionary with the cleaned values\n",
    "        data[key] = cleaned_values\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "b327033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your clean twitter data here\n",
    "cleaned_description_dict = data_cleaning(description_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "779d129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your clean lyric data here\n",
    "cleaned_lyrics_dict = data_cleaning(lyrics_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd0179",
   "metadata": {},
   "source": [
    "## Basic Descriptive Statistics\n",
    "\n",
    "Call your `descriptive_stats` function on both your lyrics data and your twitter data and for both artists (four total calls). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "2edb46f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, generate function to tokenize and filter data \n",
    "def tokenize_artist_filter(text, artist):\n",
    "    '''This function tokenizes the text in a text dictionary. \n",
    "    Additionally, it takes artist filters as input so that only\n",
    "    text associated with a specific artist key is tokenized. '''\n",
    "    if artist in text:\n",
    "        combined_text = ' '.join([str(value) for key, value in text.items() if key == artist])\n",
    "        text_tokens = word_tokenize(combined_text)\n",
    "        return text_tokens\n",
    "    else:\n",
    "        print(f\"Artist '{artist}' not found in the dictionary.\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "355c0ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_tokens_cher = tokenize_artist_filter(cleaned_lyrics_dict, 'cher')\n",
    "lyric_tokens_robyn = tokenize_artist_filter(cleaned_lyrics_dict, 'robyn')\n",
    "description_tokens_cher = tokenize_artist_filter(cleaned_description_dict, 'cher')\n",
    "description_tokens_robyn = tokenize_artist_filter(cleaned_description_dict, 'robynkonichiwa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "f0bbedd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cher lyrics - descriptive statistics:\n",
      "\n",
      "There are 948 tokens in the data.\n",
      "There are 320 unique tokens in the data.\n",
      "There are 5629 characters in the data.\n",
      "The lexical diversity is 0.338 in the data.\n",
      "\n",
      "\n",
      "Robyn lyrics - descriptive statistics:\n",
      "\n",
      "There are 312 tokens in the data.\n",
      "There are 108 unique tokens in the data.\n",
      "There are 1680 characters in the data.\n",
      "The lexical diversity is 0.346 in the data.\n",
      "\n",
      "Cher twitter profile descriptions - descriptive statistics:\n",
      "\n",
      "There are 19940092 tokens in the data.\n",
      "There are 1600885 unique tokens in the data.\n",
      "There are 99570808 characters in the data.\n",
      "The lexical diversity is 0.080 in the data.\n",
      "\n",
      "Robyn twitter profile descriptions - descriptive statistics:\n",
      "\n",
      "There are 1893275 tokens in the data.\n",
      "There are 273748 unique tokens in the data.\n",
      "There are 9754444 characters in the data.\n",
      "The lexical diversity is 0.145 in the data.\n"
     ]
    }
   ],
   "source": [
    "# calls to descriptive_stats here\n",
    "print(\"Cher lyrics - descriptive statistics:\\n\")\n",
    "lyrics_descriptive_stats = descriptive_stats(lyric_tokens_cher)\n",
    "\n",
    "print(\"\\n\\nRobyn lyrics - descriptive statistics:\\n\")\n",
    "lyrics_descriptive_stats = descriptive_stats(lyric_tokens_robyn)\n",
    "\n",
    "print(\"\\nCher twitter profile descriptions - descriptive statistics:\\n\")\n",
    "lyrics_descriptive_stats = descriptive_stats(description_tokens_cher)\n",
    "\n",
    "print(\"\\nRobyn twitter profile descriptions - descriptive statistics:\\n\")\n",
    "lyrics_descriptive_stats = descriptive_stats(description_tokens_robyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46294409",
   "metadata": {},
   "source": [
    "Q: How do you think the \"top 5 words\" would be different if we left stopwords in the data? \n",
    "\n",
    "A: If stopwords were left in the data, I believe that the top 5 words would be composed of stopwords. Stopwords are super common and frequent as they are critical for grammar and sentence structure. \n",
    "\n",
    "---\n",
    "\n",
    "Q: What were your prior beliefs about the lexical diversity between the artists? Does the difference (or lack thereof) in lexical diversity between the artists conform to your prior beliefs? \n",
    "\n",
    "A: I have never listened to Robyn, so I didn't have prior beliefs between the two artists. However, I was surpised to see that Cher's lexical diversity was only 10.6%. I imagined a higher number, perhaps around 20 or 30% especially because we excluded stopwords. Therefore, the lexical diversity rate did not conform to my prior beliefs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e1ac1",
   "metadata": {},
   "source": [
    "\n",
    "## Specialty Statistics\n",
    "\n",
    "The descriptive statistics we have calculated are quite generic. You will now calculate a handful of statistics tailored to these data.\n",
    "\n",
    "1. Ten most common emojis by artist in the twitter descriptions.\n",
    "1. Ten most common hashtags by artist in the twitter descriptions.\n",
    "1. Five most common words in song titles by artist. \n",
    "1. For each artist, a histogram of song lengths (in terms of number of tokens) \n",
    "\n",
    "We can use the `emoji` library to help us identify emojis and you have been given a function to help you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "753a5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(emoji.is_emoji(\"❤️\"))\n",
    "assert(not emoji.is_emoji(\":-)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986fc4c0",
   "metadata": {},
   "source": [
    "### Emojis 😁\n",
    "\n",
    "\n",
    "What are the ten most common emojis by artist in the twitter descriptions? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "269cd433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common emojis of twitter users following Cher: \n",
      "\n",
      "['❤️', '♥', '❤', '✨', '🌈', '💙', '🇺🇸', '💜', '💕', '🌊']\n",
      "\n",
      "\n",
      " Most common emojis of twitter users following Robyn: \n",
      "\n",
      "['♥', '❤️', '✨', '❤', '🌈', '🎶', '💜', '🎧', '🖤', '💙']\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "#generate emoji function \n",
    "def top_x_emojis(text):\n",
    "    '''this '''\n",
    "    #can change value of x is desired. the # of top emojis to be counted\n",
    "    x=10\n",
    "    emojis = [char for char in text if emoji.is_emoji(char)]\n",
    "    emoji_counts = Counter(emojis)\n",
    "    # Get the top 10 emojis with the highest counts\n",
    "    top_10_emojis = emoji_counts.most_common(10)\n",
    "    return top_10_emojis\n",
    "\n",
    "cher_top_10_emojis = top_x_emojis(description_tokens_cher)\n",
    "print(\"Most common emojis of twitter users following Cher: \\n\")\n",
    "print([emoji for emoji, _ in cher_top_10_emojis])\n",
    "\n",
    "robyn_top_10_emojis = top_x_emojis(description_tokens_robyn)\n",
    "print(\"\\n\\n Most common emojis of twitter users following Robyn: \\n\")\n",
    "print([emoji for emoji, _ in robyn_top_10_emojis])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab9b770",
   "metadata": {},
   "source": [
    "### Hashtags\n",
    "\n",
    "What are the ten most common hashtags by artist in the twitter descriptions? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "007cf593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#important to note that the '#' characters were removed during our initial data cleaning.\n",
    "\n",
    "#use unclean: description_dict\n",
    "#tokenize description_dict cher\n",
    "\n",
    "descriptions_combined_cher_unclean= ' '.join([str(value) for key, value in description_dict.items() if key == 'cher'])\n",
    "descriptions_combined_robyn_unclean= ' '.join([str(value) for key, value in description_dict.items() if key == 'robynkonichiwa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "91d32f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common hashtags of artists following Cher: \n",
      "\n",
      "['#resist', '#blm', '#blacklivesmatter', '#theresistance', '#fbr', '#resistance', '#', '#1', '#voteblue', '#lgbtq']\n",
      "\n",
      "\n",
      "Most common hashtags of artists following Robyn: \n",
      "\n",
      "['#blacklivesmatter', '#blm', '#music', '#1', '#', '#teamfollowback', '#edm', '#lgbtq', '#resist', '#art']\n"
     ]
    }
   ],
   "source": [
    "#Your code here\n",
    "\n",
    "def top_x_hashtags(text):\n",
    "    x = 10\n",
    "    text = text.lower()\n",
    "    text_without_punctuation = ''.join(char if char == '#' or char not in punctuation else ' ' for char in text)\n",
    "    tokens = text_without_punctuation.split()\n",
    "    hashtags = [token for token in tokens if token.startswith('#')]\n",
    "    #count number of hashtags\n",
    "    hashtag_counts = Counter(hashtags)\n",
    "    # get the top x number of hashtags\n",
    "    top_x_hashtags = hashtag_counts.most_common(x)\n",
    "    top_hashtags = [hashtag for hashtag, _ in top_x_hashtags]\n",
    "    return top_hashtags\n",
    "\n",
    "#extract top 10 hashtags for each artist\n",
    "top_10_hashtags_cher = top_x_hashtags(descriptions_combined_cher_unclean)\n",
    "top_10_hashtags_robyn = top_x_hashtags(descriptions_combined_robyn_unclean)\n",
    "\n",
    "#print results\n",
    "print(\"Most common hashtags of artists following Cher: \\n\")\n",
    "print(top_10_hashtags_cher)\n",
    "\n",
    "print(\"\\n\\nMost common hashtags of artists following Robyn: \\n\")\n",
    "print(top_10_hashtags_robyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f21d5",
   "metadata": {},
   "source": [
    "### Song Titles\n",
    "\n",
    "What are the five most common words in song titles by artist? The song titles should be on the first line of the lyrics pages, so if you have kept the raw file contents around, you will not need to re-read the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "bb69b36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "#function to extract titles\n",
    "def extract_song_titles(lyrics_dict):\n",
    "    '''Extracts the title of each song from the lyrics dictionary.'''\n",
    "    song_titles = {}\n",
    "    for artist, songs in lyrics_dict.items():\n",
    "        for song, lyrics in songs.items():\n",
    "            # if lyrics exist...\n",
    "            if lyrics:\n",
    "                # extract the title (all the text prior to line break)\n",
    "                title = lyrics.split('\\n')[0]\n",
    "                # store title under artist key in song dictionary\n",
    "                song_titles.setdefault(artist, []).append(title)\n",
    "    return song_titles\n",
    "\n",
    "#extract song titles\n",
    "titles = extract_song_titles(lyrics_dict)\n",
    "#clean the song titles\n",
    "titles_cleaned = data_cleaning(titles)\n",
    "\n",
    "#combine, clean, tokenize all cher and robyn songs (filtered seperately)\n",
    "combined_titles_cher = ' '.join([str(value) for key, value in titles_cleaned.items() if key == 'cher'])\n",
    "combined_titles_robyn = ' '.join([str(value) for key, value in titles_cleaned.items() if key == 'robyn'])\n",
    "\n",
    "cleaned_combined_titles_cher = ''.join([char for char in combined_titles_cher if char not in punctuation])\n",
    "cleaned_combined_titles_cher_tokenized = word_tokenize(cleaned_combined_titles_cher)\n",
    "\n",
    "cleaned_combined_titles_robyn = ''.join([char for char in combined_titles_robyn if char not in punctuation])\n",
    "cleaned_combined_titles_robyn_tokenized = word_tokenize(cleaned_combined_titles_robyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "dc1b2621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_5_words(tokenized_text):\n",
    "    '''This function extracts the most common 5 words'''\n",
    "    #count number of each word\n",
    "    word_counts = Counter(tokenized_text)\n",
    "    #get and return the top 5 words\n",
    "    top_5 = [word for word, _ in word_counts.most_common(5)]\n",
    "    return top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "b362dc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five most common words in Cher song titles:\n",
      "\n",
      "['love', 'man', 'song', 'dont', 'come']\n",
      "\n",
      "\n",
      "Five most common words in Robyn song titles:\n",
      "\n",
      "['love', 'dont', 'u', 'hang', 'tell']\n"
     ]
    }
   ],
   "source": [
    "# get the top 5 words from both cher and robyn\n",
    "title_cher_top_5_words = top_5_words(cleaned_combined_titles_cher_tokenized)\n",
    "title_robyn_top_5_words = top_5_words(cleaned_combined_titles_robyn_tokenized)\n",
    "\n",
    "#print the results\n",
    "print(\"Five most common words in Cher song titles:\\n\")\n",
    "print(title_cher_top_5_words)\n",
    "\n",
    "print(\"\\n\\nFive most common words in Robyn song titles:\\n\")\n",
    "print(title_robyn_top_5_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd4fd71",
   "metadata": {},
   "source": [
    "### Song Lengths\n",
    "\n",
    "For each artist, a histogram of song lengths (in terms of number of tokens). If you put the song lengths in a data frame with an artist column, matplotlib will make the plotting quite easy. An example is given to help you out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "f92a9546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "Artist 1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Artist 2    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: length, dtype: object"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_replicates = 1000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"artist\" : ['Artist 1'] * num_replicates + ['Artist 2']*num_replicates,\n",
    "    \"length\" : np.concatenate((np.random.poisson(125,num_replicates),np.random.poisson(150,num_replicates)))\n",
    "})\n",
    "\n",
    "df.groupby('artist')['length'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde9ebb",
   "metadata": {},
   "source": [
    "Since the lyrics may be stored with carriage returns or tabs, it may be useful to have a function that can collapse whitespace, using regular expressions, and be used for splitting. \n",
    "\n",
    "Q: What does the regular expression `'\\s+'` match on? \n",
    "\n",
    "A: This regular expression matches on one or more instances of any whitespace character. Whitespace characters include spaces, tabs, as well as new lines. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "f0e34516",
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_whitespace = re.compile(r'\\s+')\n",
    "\n",
    "def tokenize_lyrics(lyrics):\n",
    "    '''this function splits/collapses lyrics on whitespace'''\n",
    "    lines = lyrics.split('\\n')\n",
    "    #exclude the title\n",
    "    lyrics_without_title = '\\n'.join(lines[1:])\n",
    "    # Tokenize the lyrics without the title\n",
    "    tokens = word_tokenize(lyrics_without_title)\n",
    "    return tokens\n",
    "\n",
    "def count_tokens(dictionary):\n",
    "    ''' this function counts the number of tokens (song lyrics) in dictionary'''\n",
    "    token_counts = []\n",
    "    for artist, songs in dictionary.items():\n",
    "        for song, lyrics in songs.items():\n",
    "            # tokenize lyrics\n",
    "            tokens = tokenize_lyrics(lyrics)\n",
    "            # store the number of tokens (length)\n",
    "            length = len(tokens)\n",
    "            # append artist name and associated token count to list\n",
    "            token_counts.append({'artist': artist, 'length': length})\n",
    "    # save dictionary list as dataframe\n",
    "    df = pd.DataFrame(token_counts)\n",
    "    return df\n",
    "\n",
    "song_lengths = count_tokens(lyrics_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "2294c440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "cher     AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "robyn    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: length, dtype: object"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your lyric length comparison chart here. \n",
    "\n",
    "\\\n",
    "song_lengths.groupby('artist')['length'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
